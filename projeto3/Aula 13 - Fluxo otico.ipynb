{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluxo ótico\n",
    "\n",
    "Considere dois quadros sucessivos de um video, e concentre-se em um ponto do espaço onde um objeto em movimento aparece. O que acontece com as imagens dos quadros de video neste ponto? Qual a relação entre $I(x,y,t)$ e $I(x,y,t + \\Delta t)$?\n",
    "\n",
    "Vamos analisar os quadros do video a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "cap = cv2.VideoCapture('slow_traffic_small.mp4')\n",
    "\n",
    "_, frame = cap.read()\n",
    "\n",
    "while frame is not None:\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    _, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos nos concentrar nas regiões delimitadas abaixo, nos quadros $100$ e $101$. A região $1$ apresenta movimento, enquanto a região $2$ é um segmento estático do video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def add_box(reg, color, label):\n",
    "    x, y, width, height = reg\n",
    "    plt.gca().add_patch(Rectangle((x, y), width, height, linewidth=1, edgecolor=color, facecolor='none'))\n",
    "    plt.text(x, y - 5, label, color=color)\n",
    "\n",
    "img_antes = cv2.imread('./Imagens/frame_0100.png')\n",
    "img_depois = cv2.imread('./Imagens/frame_0101.png')\n",
    "\n",
    "reg1 = (400, 250, 50, 50)\n",
    "reg2 = (400, 75, 50, 50)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(img_antes[:, :, ::-1])\n",
    "add_box(reg1, 'red', 'Região 1')\n",
    "add_box(reg2, 'blue', 'Região 2')\n",
    "plt.title('Antes')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(img_depois[:, :, ::-1])\n",
    "add_box(reg1, 'red', 'Região 1')\n",
    "add_box(reg2, 'blue', 'Região 2')\n",
    "plt.title('Depois')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos observar as regiões em detalhe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corta_reg(img, reg):\n",
    "    x, y, width, height = reg\n",
    "    if len(img.shape) == 2:\n",
    "        return img[y:(y+height), x:(x+width)]\n",
    "    else:\n",
    "        return img[y:(y+height), x:(x+width), :]\n",
    "\n",
    "def show_reg(img, reg):\n",
    "    if len(img.shape) == 2:\n",
    "        plt.imshow(corta_reg(img, reg)[:, :], cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(corta_reg(img, reg)[:, :, ::-1])\n",
    "\n",
    "plt.figure(figsize=(16,16)) \n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "show_reg(img_antes, reg1)\n",
    "plt.title('Antes, região 1')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "show_reg(img_depois, reg1)\n",
    "plt.title('Depois, região 1')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "show_reg(img_antes, reg2)\n",
    "plt.title('Antes, região 2')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "show_reg(img_depois, reg2)\n",
    "plt.title('Depois, região 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que houve alguma mudança na região $1$, onde temos um carro em movimento, mas não na região $2$. \n",
    "\n",
    "Vamos trabalhar apenas com a imagem em tons de cinza, meramente para simplificar nossa explicação matemática a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_antes_gray = cv2.cvtColor(img_antes, cv2.COLOR_BGR2GRAY) / 255.0\n",
    "img_depois_gray = cv2.cvtColor(img_depois, cv2.COLOR_BGR2GRAY) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note a diferença entre quadros ponto-a-ponto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_diff_reg_1 = corta_reg(img_depois_gray, reg1) - corta_reg(img_antes_gray, reg1)\n",
    "img_diff_reg_2 = corta_reg(img_depois_gray, reg2) - corta_reg(img_antes_gray, reg2)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_diff_reg_1, vmin = -1.0, vmax = 1.0, cmap='gray')\n",
    "plt.title(f'Região 1, diff em [{np.min(img_diff_reg_1):.2f}, {np.max(img_diff_reg_1):.2f}]')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_diff_reg_2, vmin = -1.0, vmax = 1.0, cmap='gray')\n",
    "plt.title(f'Região 2, diff em [{np.min(img_diff_reg_2):.2f}, {np.max(img_diff_reg_2):.2f}]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que houve bastante mudança na região $1$ e pouca mudança na região $2$. \n",
    "\n",
    "Prestando atenção no detalhe do detalhe vermelho do parachoque, podemos estimar que o movimento vertical da imagem do carro foi para baixo e para a direita. Vamos comparar este detalhe entre os sucesssivos quadros, mas incorporando a translação no quadro posterior. O valor da translação é mágico, por enquanto..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [1.0, 0.0, -0.58],  # 1.8 para baixo.\n",
    "    [0.0, 1.0, -0.23],  # 0.7 para a direita.\n",
    "])\n",
    "\n",
    "img_depois_gray_transl = cv2.warpAffine(img_depois_gray, M, None)\n",
    "img_diff_transl = corta_reg(img_depois_gray_transl, reg1) - corta_reg(img_depois_gray, reg1)\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "show_reg(img_antes_gray, reg1)\n",
    "plt.title('Região 1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "show_reg(img_depois_gray_transl, reg1)\n",
    "plt.title('Região 1 transladada')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_diff_transl, vmin = -1.0, vmax = 1.0, cmap='gray')\n",
    "plt.title(f'Região 2, diff em [{np.min(img_diff_transl):.2f}, {np.max(img_diff_transl):.2f}]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a diferença entre quadros diminuiu ao se incorporar a translação, como esperado.\n",
    "\n",
    "Desta observação vem a idéia central da técnica de *fluxo ótico*: determinar para cada ponto da imagem uma translação tal que:\n",
    "\n",
    "$$\n",
    "I(x, y, t) = I(x + \\Delta x, y + \\Delta y, t + \\Delta t)\n",
    "$$\n",
    "\n",
    "onde $\\Delta t$ é o espaçamento temporal entre quadros, $\\Delta x$ e $\\Delta y$ são o deslocamento do objeto entre quadros. Esta é a hipótese do fluxo ótico.\n",
    "\n",
    "Nosso objetivo é determinal $\\Delta x$ e $\\Delta y$. Decompondo $I(x + \\Delta x, y + \\Delta y, t + \\Delta t)$ em série de Taylor temos:\n",
    "\n",
    "$$\n",
    "I(x + \\Delta x, y + \\Delta y, t + \\Delta t) \\approx I(x, y, t) \n",
    "+ \\frac{\\partial I}{\\partial x}(x, y, t) \\Delta x \n",
    "+ \\frac{\\partial I}{\\partial y}(x, y, t) \\Delta y\n",
    "+ \\frac{\\partial I}{\\partial t}(x, y, t) \\Delta t \n",
    "$$\n",
    "\n",
    "Substituindo a hipótese do fluxo ótico temos:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial I}{\\partial x}(x, y, t) \\Delta x \n",
    "+ \\frac{\\partial I}{\\partial y}(x, y, t) \\Delta y\n",
    "+ \\frac{\\partial I}{\\partial t}(x, y, t) \\Delta t = 0\n",
    "$$\n",
    "\n",
    "Dividindo por $\\Delta t$ obtemos:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial I}{\\partial x}(x, y, t) v_x(x, y, t)\n",
    "+ \\frac{\\partial I}{\\partial y}(x, y, t) v_y(x, y, t) + \\frac{\\partial I}{\\partial t}(x, y, t) = 0\n",
    "$$\n",
    "\n",
    "Para maior clareza, vamos remover as indicações de coordenadas $(x, y, t)$, e abreviar as derivadas parciais em $x$, $y$ e $t$ por $I_x$, $I_y$ e $I_t$ respectivamente. A equação acima fica sendo:\n",
    "\n",
    "$$\n",
    "I_x v_x + I_y v_y + I_t = 0\n",
    "$$\n",
    "\n",
    "Temos apenas uma equação e duas incógnitas. Como resolver esse problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_antes_gray\n",
    "\n",
    "kd, k = cv2.getDerivKernels(1, 0, 1, normalize=True)\n",
    "\n",
    "print('Kernel para derivada')\n",
    "print(kd)\n",
    "\n",
    "print('Kernel sem derivada')\n",
    "print(k)\n",
    "\n",
    "Ix = cv2.sepFilter2D(img, -1, kd, k)\n",
    "Iy = cv2.sepFilter2D(img, -1, k, kd)\n",
    "It= img_depois_gray - img_antes_gray\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('img')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(Ix, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('$I_x$')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(Iy, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('$I_y$')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(It, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('$I_t$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Lucas-Kanade\n",
    "\n",
    "A idéia do algoritmo de Lucas-Kanade é supor que o movimento é mais ou menos constante em uma vizinhança em torno de um pixel dado. Isso vai falhar nas bordas de objetos, mas paciência. Dentro dessa hipótese, vamos considerar uma vizinhança ${x_i, y_i}$ em torno de $(x, y)$, e escrever a equação do fluxo ótico para cada um desses pontos, mas mantendo o mesmo $v_x$ e $v_y$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "& I_x(x_1, y_1, t) v_x + I_y(x_1, y_1, t) v_y + I_t(x_1, y_1, t) = 0 \\\\\n",
    "& I_x(x_2, y_2, t) v_x + I_y(x_2, y_2, t) v_y + I_t(x_2, y_2, t) = 0 \\\\\n",
    "& \\vdots \\\\\n",
    "& I_x(x_n, y_n, t) v_x + I_y(x_n, y_n, t) v_y + I_t(x_n, y_n, t) = 0 \n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Agora temos o problema oposto: muitas equações para apenas duas incógnitas!\n",
    "\n",
    "Vamos modificar um pouco o sistema de equações e introduzir um termo de \"erro\" em cada equação. Esta é a abordagem padrão do *método dos mínimos quadrados*:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "& I_x(x_1, y_1, t) v_x + I_y(x_1, y_1, t) v_y + I_t(x_1, y_1, t) = \\varepsilon_1 \\\\\n",
    "& I_x(x_2, y_2, t) v_x + I_y(x_2, y_2, t) v_y + I_t(x_2, y_2, t) = \\varepsilon_2 \\\\\n",
    "& \\vdots \\\\\n",
    "& I_x(x_n, y_n, t) v_x + I_y(x_n, y_n, t) v_y + I_t(x_n, y_n, t) = \\varepsilon_n \n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Em notação matricial, temos:\n",
    "\n",
    "$$\n",
    "\\underbrace{\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "I_x(x_1, y_1, t) & I_y(x_1, y_1, t)\\\\\n",
    "I_x(x_2, y_2, t) & I_y(x_2, y_2, t)\\\\\n",
    "\\vdots & \\vdots\\\\\n",
    "I_x(x_n, y_n, t) & I_y(x_n, y_n, t) \n",
    "\\end{matrix}\n",
    "\\right]\n",
    "}_{\\mathbf{A}} \n",
    "\\underbrace{\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "v_x \\\\\n",
    "v_y\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "}_{\\mathbf{v}}\n",
    "-\n",
    "\\underbrace{\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "-I_t(x_1, y_1, t)\\\\\n",
    "-I_t(x_2, y_2, t)\\\\\n",
    "\\vdots\\\\\n",
    "-I_t(x_n, y_n, t)\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "}_{\\mathbf{b}}\n",
    "=\n",
    "\\underbrace{\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\varepsilon_1\\\\\n",
    "\\varepsilon_2\\\\\n",
    "\\vdots\\\\\n",
    "\\varepsilon_n\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "}_{\\mathbf{\\varepsilon}}\n",
    "$$\n",
    "\n",
    "ou \n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{v} - \\mathbf{b} = \\mathbf{\\varepsilon}\n",
    "$$\n",
    "\n",
    "A soma dos quadrados das componentes de erro é:\n",
    "\n",
    "$$\n",
    "S = \\sum_{i = 1}^{n} \\varepsilon_i^2 = \\mathbf{\\varepsilon}^T \\mathbf{\\varepsilon}\n",
    "$$\n",
    "\n",
    "Queremos encontrar um valor de $\\mathbf{v}$ que minimize $S$. Substituindo a equação anterior temos:\n",
    "\n",
    "$$\n",
    "S = (\\mathbf{A} \\mathbf{v} - \\mathbf{b})^T (\\mathbf{A} \\mathbf{v} - \\mathbf{b}) = \n",
    "\\mathbf{v}^T \\mathbf{A}^T \\mathbf{A} \\mathbf{v} \n",
    "    - 2 \\mathbf{v}^T \\mathbf{A}^T \\mathbf{b}\n",
    "    + \\mathbf{b}^T \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Derivando em relação a $\\mathbf{v}$ (veja https://en.wikipedia.org/wiki/Matrix_calculus) temos o seguinte:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial}{\\partial \\mathbf{v}} \\left(\\mathbf{v}^T \\mathbf{A}^T \\mathbf{A} \\mathbf{v}\\right) & = 2 \\mathbf{A}^T \\mathbf{A} \\mathbf{v}\\\\\n",
    "\\frac{\\partial}{\\partial \\mathbf{v}} \\left(\\mathbf{v}^T \\mathbf{A}^T \\mathbf{b}\\right) & = \\mathbf{A}^T \\mathbf{b} \\\\\n",
    "\\frac{\\partial}{\\partial \\mathbf{v}} \\left(\\mathbf{b}^T \\mathbf{b}\\right) & = 0 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Consequentemente, tomando a derivada de $S$ em relação a $\\mathbf{v}$ temos:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial S}{\\partial \\mathbf{v}} = 2 \\mathbf{A}^T \\mathbf{A} \\mathbf{v} - 2 \\mathbf{A}^T \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Igualando esta expressão a zero ***e supondo que $\\mathbf{A}^T \\mathbf{A}$ é inversível*** obtemos a solução do nosso problema:\n",
    "\n",
    "$$\n",
    "2 \\mathbf{A}^T \\mathbf{A} \\mathbf{v} - 2 \\mathbf{A}^T \\mathbf{b} = 0 \\Longrightarrow \\mathbf{v} = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Substituindo as definições dos vários termos, temos a forma final da expressão de calculo do fluxo otico em um ponto $(x, y, t)$:\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "v_x \\\\\n",
    "v_y\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "=\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\sum I_x^2 & \\sum I_x I_y\\\\\n",
    "\\sum I_x I_y & \\sum I_y ^2\\\\\n",
    "\\end{matrix}\n",
    "\\right]^{-1}\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "-\\sum I_x I_t\\\\\n",
    "-\\sum I_y I_t\\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "**Atividade**: Calcule o deslocamento ótimo para o nosso caso de exemplo usando o resultado acima.\n",
    "\n",
    "Dica: $\\sum I_x^2$ é simplesmente `np.sum(Ix*Ix)`, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É razoavelmente simples calcular o deslocamento ótimo para todos os pontos da imagem usando numpy:\n",
    "\n",
    "- Como a matriz $\\mathbf{A}$ é de tamanho $2 \\times 2$, podemos determinar sua inversa algebricamente sem maiores problemas. \n",
    "- Os somatórios locais podem ser calculados com convolução.\n",
    "- As operações pixel-a-pixel podem ser feitas como somas e multiplicações de arrays no numpy\n",
    "\n",
    "Trata-se de uma implementação \"caseira\" de fluxo ótico, mas já dá para usar para aprender sobre o método.\n",
    "\n",
    "Antes de prosseguir, temos um problema: o que acontece se a matriz $\\mathbf{A}$ não for \"bem inversível\"? Por enquanto vamos pular esse problema com uma gambiarra numérica - veja no código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.GaussianBlur(Ix*Ix, (15, 15), 3)\n",
    "b = cv2.GaussianBlur(Ix*Iy, (15, 15), 3)\n",
    "c = cv2.GaussianBlur(Iy*Iy, (15, 15), 3)\n",
    "d = -cv2.GaussianBlur(Ix*It, (15, 15), 3)\n",
    "e = -cv2.GaussianBlur(Iy*It, (15, 15), 3)\n",
    "\n",
    "det = a*c - b*b\n",
    "inv_det = np.sign(det) * (1.0 / (np.abs(det) + 1e-4))\n",
    "\n",
    "vx = (c*d - b*e) * inv_det\n",
    "vy = (a*e - b*d) * inv_det\n",
    "\n",
    "vmag = np.sqrt(vx**2 + vy**2)\n",
    "vang = np.arctan2(vy, vx)\n",
    "\n",
    "\n",
    "vmask = vmag < np.percentile(vmag, 90)\n",
    "vang[vmask] = 0.0\n",
    "\n",
    "plt.figure(figsize=(16, 15))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.imshow(img_antes[:,:,::-1], cmap='gray')\n",
    "plt.title('Antes')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.imshow(img_depois[:,:,::-1], cmap='gray')\n",
    "plt.title('Depois')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.imshow(vx, cmap='gray')\n",
    "plt.title(f'{np.min(vx):.2f} $\\leq v_x \\leq$ {np.max(vx):.2f} ')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.imshow(vy, cmap='gray')\n",
    "plt.title(f'{np.min(vy):.2f} $\\leq v_y \\leq$ {np.max(vy):.2f} ')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.imshow(vmag, cmap='gray')\n",
    "plt.title(f'{np.min(vmag):.2f} $\\leq |\\mathbf{{v}}| \\leq$ {np.max(vmag):.2f} ')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.imshow(vang, cmap='gray')\n",
    "plt.title(f'{np.min(vang):.2f} $\\leq ang(\\mathbf{{v}}) \\leq$ {np.max(vang):.2f} ')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os pontos onde o deslocamento for melhor calculado são as regiões não-planas, preferencialmente as quinas ou cruzamentos...\n",
    "\n",
    "## O problema do condicionamento de $\\mathbf{A}$: *Good Features to Track*\n",
    "\n",
    "É fundamental que a matriz $\\mathbf{A}$ seja \"bem inversível\", caso contrário não teremos boa acurácia numérica no método, ou mesmo não teremos nem ao menos a derivada!\n",
    "\n",
    "O que quer dizer \"bem inversível\"? Para que não tenhamos uma explosão numérica no processo de inversão de matriz, é necessário que ambos os autovalores de $\\mathbf{A}$ tenham magnitude bem maior que zero, e que tais magnitudes sejam similares entre si.\n",
    "\n",
    "Oras, essas são exatamente as condições do detector de Shi-Tomasi, o \"Good Features To Track\"! Agora ficou claro o porquê do nome deste detector de características visuais. \n",
    "\n",
    "## Como detectar grandes deslocamentos?\n",
    "\n",
    "Todo o algoritmo está baseado na expansão em série de Taylor para um deslocamento pequeno. Como fazer para detectar um deslocamento grande?\n",
    "\n",
    "Um deslocamento grande pode ser visto como um deslocamento pequeno, mas em uma escala maior! Uma ideia portanto seria:\n",
    "\n",
    "1. Decompor os quadros em pirâmide.\n",
    "2. Executar o Shi-Tomasi para descobrir pontos notáveis na escala maior em ambos os quadros.\n",
    "3. Efetuar o Lucas-Kanade para determinar o fluxo ótico em torno de cada ponto notável, e fazer a correspondência entre pontos notáveis dos quadros anterior e posterior (rastreamento intra-escala).\n",
    "4. Subir um nível na pirâmide, refazer o Shi-Tomasi e fazer a correspondência entre pontos notáveis de escalas diferentes (rastreamento inter-escala)\n",
    "5. Repetir passo 4 até o fim das escalas.\n",
    "\n",
    "Esta é a implementação do Lucas-Kanade piramidal, descrita no artigo de Bouguet (ver no Blackboard), e está implementada no método `cv2.calcOpticalFlowPyrLK()`. Veja abaixo um exemplo de rastreamento de movimento usando essa técnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado do exemplo do OpenCV em https://docs.opencv.org/ref/master/d4/dee/tutorial_optical_flow.html\n",
    "cap = cv2.VideoCapture('slow_traffic_small.mp4')\n",
    "\n",
    "# Troque a linha anterior pela linha seguinte para usar a cãmera do laptop.\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection.\n",
    "feature_params = {\n",
    "    'maxCorners': 100,\n",
    "    'qualityLevel': 0.3,\n",
    "    'minDistance': 7,\n",
    "    'blockSize': 7\n",
    "}\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow.\n",
    "lk_params = {\n",
    "    'winSize': (15, 15),\n",
    "    'maxLevel': 2,\n",
    "    'criteria': (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "}\n",
    "\n",
    "# Create some random colors.\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Take first frame and find corners in it.\n",
    "_, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes.\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "        \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow.\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points.\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Draw the tracks.\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points.\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto 2-1: Estabilização de imagens\n",
    "\n",
    "**Motivação**: https://www.youtube.com/watch?v=4vt7bGEen2s\n",
    "\n",
    "Agora que você consegue capturar o fluxo ótico entre duas imagens consecultivas, vamos utilizá-lo de modo inverso: como seria uma forma de compensar eventuais oscilações na câmera?\n",
    "\n",
    "Projete um programa que captura as imagens da webcam e realiza a estabilização da imagem. Você notará que se utilizar o programa acima, a estabilização será parcial e falha. Por que?\n",
    "\n",
    "Você deve construir um Jupyter Notebook que utiliza o fluxo ótico para corrigir o problema acima. O notebook deve conter comentários acerca da solução usada. Você pode usar o algoritmo Lucas-Kanade piramidal, explicado neste notebook, ou o algoritmo de fluxo otico denso (algoritmo de Farneback) implementado na função `cv2.calcOpticalFlowFarneback()` (que vai provavelmente ser muito mais simples para videos pequenos!)\n",
    "\n",
    "O programa base para uso da webcam:\n",
    "\n",
    "```Python\n",
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    " \n",
    "while True:\n",
    "    _, frame = captura.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "        \n",
    "    cv2.imshow(\"Video\", frame)\n",
    "   \n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    " \n",
    "captura.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "### Entrega: 25/Set 23:59 via GitHub.\n",
    "\n",
    "### Rubrica do Projeto:\n",
    "\n",
    "    I. Não entregou ou entregou apenas um rascunho.\n",
    "    D. O programa faz apenas uma estabilização parcial com os programas da aula de hoje.\n",
    "    C. Utiliza o fluxo otico de uma janela no centro da imagem.\n",
    "    B. Utiliza meios para compensar as faixas pretas nos cantos da imagem com algum limite.\n",
    "    A. Consegue realizar a compensação em rotação no eixo de profundidade.\n",
    "    \n",
    "    +1/2 Conceito para implementações que comprovadamente melhoram o desempenho da estabilização.\n",
    "    -1/2 Conceito se o notebook não contiver uma explicação detalhada da solução apresentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado do exemplo do OpenCV em https://docs.opencv.org/ref/master/d4/dee/tutorial_optical_flow.html\n",
    "#cap = cv2.VideoCapture('slow_traffic_small.mp4')\n",
    "\n",
    "# Troque a linha anterior pela linha seguinte para usar a cãmera do laptop.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection.\n",
    "feature_params = {\n",
    "    'maxCorners': 100,\n",
    "    'qualityLevel': 0.3,\n",
    "    'minDistance': 7,\n",
    "    'blockSize': 7\n",
    "}\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow.\n",
    "lk_params = {\n",
    "    'winSize': (15, 15),\n",
    "    'maxLevel': 2,\n",
    "    'criteria': (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "}\n",
    "\n",
    "# Create some random colors.\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Take first frame and find corners in it.\n",
    "_, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes.\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "movx=0\n",
    "movy=0\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "        \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #frame_gray = frame_gray[300:300][300:300][:]\n",
    "\n",
    "    # Calculate optical flow.\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        old_gray, frame_gray, p0, None, **lk_params)\n",
    "    \n",
    "    vecx = []\n",
    "    vecy = []\n",
    "    \n",
    "    try: \n",
    "        for i,(point) in enumerate(p1):\n",
    "            vec_p = (point[0]-(p0[i][0]))\n",
    "\n",
    "            vecx.append((vec_p[0]))\n",
    "            vecy.append((vec_p[1]))\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    movx += np.average(vecx)\n",
    "    movy += np.average(vecy)\n",
    "    \n",
    "    M = np.array([[1,0,-movx],[0,1,-movy]])\n",
    "    rows,cols,channel = frame.shape\n",
    "    \n",
    "    #frame=cv2.warpAffine(frame,M,(cols,rows))\n",
    "        \n",
    "    # Select good points.\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    '''\n",
    "    # Draw the tracks.\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "    '''\n",
    "    frame = cv2.add(frame, mask)\n",
    "    img=cv2.warpAffine(frame,M,(cols,rows))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points.\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ceil(rows-movx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
